{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivaniThakur-19/Bike-Sharing-Demand-Prediction-Capstone-I/blob/main/Bike_Sharing_Demand_Prediction_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Seoul Bike Sharing Demand Prediction </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b> The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.</b>\n",
        "\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "* ### Date : year-month-day\n",
        "* ### Rented Bike count - Count of bikes rented at each hour\n",
        "* ### Hour - Hour of he day\n",
        "* ### Temperature-Temperature in Celsius\n",
        "* ### Humidity - %\n",
        "* ### Windspeed - m/s\n",
        "* ### Visibility - 10m\n",
        "* ### Dew point temperature - Celsius\n",
        "* ### Solar radiation - MJ/m2\n",
        "* ### Rainfall - mm\n",
        "* ### Snowfall - cm\n",
        "* ### Seasons - Winter, Spring, Summer, Autumn\n",
        "* ### Holiday - Holiday/No holiday\n",
        "* ### Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF9YQdOIHeue"
      },
      "source": [
        "# 1.Understanding the data:\n",
        "- Import the Libraries\n",
        "- Import the data and views it columns\n",
        "- Check all the statistics and data types of the data\n",
        "- Visualize the numerical and categorical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "outputs": [],
      "source": [
        "#import the libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as pg\n",
        "%matplotlib inline\n",
        "# import warning \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# import evaluation metrics\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
        "#import datetime library t wrok with datetime values\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "\n",
        "# import  gridsearchcv , and randomsearCV for hyperparameter tuning \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "#import other important libraries \n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# import ML models \n",
        "from sklearn.linear_model import LinearRegression,Lasso,Ridge,SGDRegressor #linear , ridge , lasso and SGD regressor\n",
        "from sklearn.preprocessing import PolynomialFeatures # for polynomial regression\n",
        "from sklearn.tree import DecisionTreeRegressor # for decision tree regressor\n",
        "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor # ensemble models\n",
        "from xgboost import XGBRegressor #for XG boost\n",
        "#\n",
        "from sklearn.datasets import make_regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jFkoGBZ2A9I"
      },
      "outputs": [],
      "source": [
        "# Mount your drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUgoQ_SaHqLT"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/SeoulBikeData.csv', encoding = ('ISO-8859-1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6KggzXKHteX"
      },
      "outputs": [],
      "source": [
        "#make copy of our datasets \n",
        "df=data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jkv5jSWd9S1Z"
      },
      "outputs": [],
      "source": [
        "# column name of our dataframe\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5eo2ai9IpGC"
      },
      "outputs": [],
      "source": [
        "#  replace columns name with the single column names\n",
        "\n",
        "df=df.rename(columns={'Rented Bike Count':'Rented_Bike_Count',\n",
        "                                'Temperature(°C)':'Temperature',\n",
        "                                'Humidity(%)':'Humidity',\n",
        "                                'Wind speed (m/s)':'Wind_speed',\n",
        "                                'Visibility (10m)':'Visibility',\n",
        "                                'Dew point temperature(°C)':'Dew_point_temperature',\n",
        "                                'Solar Radiation (MJ/m2)':'Solar_Radiation',\n",
        "                                'Rainfall(mm)':'Rainfall',\n",
        "                                'Snowfall (cm)':'Snowfall',\n",
        "                                'Functioning Day':'Functioning_Day'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JAMLoqf98dn"
      },
      "outputs": [],
      "source": [
        "# look at our new column name \n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuLzldwfIAs4"
      },
      "outputs": [],
      "source": [
        "# dataframe \n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCQErU5VIPGT"
      },
      "outputs": [],
      "source": [
        "# shape of dataset  \n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdiYhOBnIa4J"
      },
      "outputs": [],
      "source": [
        "# some basic info  \n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM73PR5GIs2g"
      },
      "outputs": [],
      "source": [
        "# to know about descriptive summary \n",
        "df.describe(include=\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0TL8uFhI4mK"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYtZbYvGOlAN"
      },
      "outputs": [],
      "source": [
        "# checking the null value in each column of datasets\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "torSSpVnsYLo"
      },
      "outputs": [],
      "source": [
        "# check no. of unique values in each columns \n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKPA1ohxDpeM"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZmJxsACz3kU"
      },
      "source": [
        "### Correlation between columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "su2b0HsWKVjK"
      },
      "outputs": [],
      "source": [
        "# ploting heat map to determine corelation b/w columns of your datasets\n",
        "plt.figure(figsize = (14,8))\n",
        "sns.heatmap(df.corr() , annot = True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9E6WJnGgFM8"
      },
      "source": [
        "# **Initial visualisation**\n",
        "\n",
        "To get a feeling for the data it is a good idea to do some form of simple visualisation.  **Display a set of histograms for the features** as they are right now, prior to any cleaning steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpftvjDJgIBX"
      },
      "outputs": [],
      "source": [
        "# Plot the data\n",
        "df.hist(bins=50,figsize=(10,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a4hETNc_UbN"
      },
      "outputs": [],
      "source": [
        "# plot the scatterplot to show missing values \n",
        "missing_values = pd.DataFrame((df.isna().sum()) * 100 / df.shape[0]).reset_index( )\n",
        "plt.figure(figsize = (10,5))\n",
        "ax = sns.scatterplot(df.columns,0,hue=0, palette=\"YlOrBr\")  \n",
        "plt.xticks(rotation =45,fontsize =12,Weight='bold')\n",
        "plt.yticks(fontsize =10,Weight='bold')\n",
        "plt.title(\"Percentage of Missing values\",Weight='bold')\n",
        "plt.ylabel(\"PERCENTAGE\",Weight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cpLnr6naWks"
      },
      "source": [
        "As we can see above there are no missing value presents thankfully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzyfyuIMI-Cn"
      },
      "outputs": [],
      "source": [
        "# to know about duplicate data in our datasets \n",
        "\n",
        "df[df.duplicated()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kYg6PZb21LQ"
      },
      "outputs": [],
      "source": [
        "# as date is object dtype, we need to convert it into date type of object\n",
        "df['Date'] = pd.to_datetime(df['Date']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2opNH4d5UVb"
      },
      "outputs": [],
      "source": [
        "# now split our date column into weekday, month , and year for better understanding \n",
        "\n",
        "df['day_of_week'] = df['Date'].dt.day_name() # extraxt weekday column from date \n",
        "df['month'] = df['Date'].dt.month_name() # extracting month column from date \n",
        "df['year'] = df['Date'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01C949N57lQr"
      },
      "outputs": [],
      "source": [
        "# now we need to covert year column into categorical column for better analytical purpose\n",
        "df['year'] = df['year'].astype('object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD0IAXszY1j0"
      },
      "outputs": [],
      "source": [
        "# now see unqiue values in year column\n",
        "df['year'].unique( )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-SR6fbxCzQm"
      },
      "outputs": [],
      "source": [
        "# convert hour column into categorical column as even though time is continous column here it's present like timestamp feature\n",
        "df['Hour']=df['Hour'].astype('object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xltTHkLuUNJ5"
      },
      "outputs": [],
      "source": [
        "# we can also segregate our day into weekdays and weekend category \n",
        "\n",
        "df['weekend_col'] = df['day_of_week'].apply(lambda x:'Weekend'  if x=='Saturday' or  x== 'Sunday' else 'Weekdays')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0oBpdk8WEEh"
      },
      "outputs": [],
      "source": [
        "# now we can drop day column of date , day(as we have extracted weekend and weekday feature from it) and we can also drop year column as ....\n",
        "# year column have date from dec 2017 and nov 2018 \n",
        "\n",
        "df= df.drop(columns = ['Date' , 'day_of_week' , 'year'] , axis =1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsPPId5Ezsbd"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGO-irS1Y38r"
      },
      "outputs": [],
      "source": [
        "# divide cour dataset on the base of categorical and numerical features \n",
        "numeric_df = df.select_dtypes(exclude='object')\n",
        "categorical_df = df.select_dtypes(include='object') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBu9y_zStckX"
      },
      "outputs": [],
      "source": [
        "numeric_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMzDRFONIGpq"
      },
      "source": [
        "# 2. Exploratary Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8KAQajTwJlo"
      },
      "outputs": [],
      "source": [
        "### Visualizing\n",
        "cols = df.columns.tolist()\n",
        "cols.remove('Rented_Bike_Count')\n",
        "\n",
        "# scatter plot\n",
        "df.plot(kind=\"line\", x=\"Rented_Bike_Count\", y=cols, subplots=True, sharex=True, ls=\"none\", marker=\"o\",figsize=(20,30),layout=(5, 3))\n",
        "\n",
        "# box plot\n",
        "df.plot(kind=\"box\", x=\"Rented_Bike_Count\", y=cols, subplots=True, sharex=True,figsize=(10,15),layout=(5, 3))\n",
        "plt.show()\n",
        "\n",
        "# show the non-numerical entries\n",
        "print(np.sum(df.isna()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DT8_5cecO4a"
      },
      "source": [
        "# Categorical columns eda "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGkxwd2HOCC4"
      },
      "outputs": [],
      "source": [
        "categorical_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32AZhfGmvl-g"
      },
      "outputs": [],
      "source": [
        "# first by months\n",
        "\n",
        "sns.catplot(x = 'month' , y = 'Rented_Bike_Count' ,kind = 'bar', height= 4.5, aspect = 2.5 , data = df)\n",
        "plt.title(\"Count of Rented bikes acording to Month\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dxL1gERyQPE"
      },
      "outputs": [],
      "source": [
        "# now by weekday and weekend\n",
        "\n",
        "sns.catplot( x= 'weekend_col' ,  y = 'Rented_Bike_Count' , data = df , kind = 'box' , height = 4.5, aspect = 2.0 )\n",
        "plt.title('Count of Rented bikes acording to weekdays')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoB-r-FLJCTu"
      },
      "outputs": [],
      "source": [
        "# now by hour coulmns \n",
        "res = sns.catplot(x= 'Hour' , y= 'Rented_Bike_Count' , data = df , kind= 'bar' , height = 10.0 , aspect = 7.0)\n",
        "res.set_xticklabels(fontsize = 26)\n",
        "res.set_yticklabels(fontsize = 30)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13NruWiaK4TY"
      },
      "outputs": [],
      "source": [
        "# now on the basis of functioning day \n",
        "\n",
        "sns.catplot(x = 'Functioning_Day',y = 'Rented_Bike_Count',data = df , kind = 'box' , height = 4.5, aspect = 2.5 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqdMIaPGOO6P"
      },
      "outputs": [],
      "source": [
        "# by season now \n",
        "sns.catplot(x = 'Seasons' , y = 'Rented_Bike_Count' , data = df , kind = 'bar' , height = 4.5 , aspect = 2.5 )\n",
        "plt.title('count od rented bike acc to season')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIkF4Q5jQHFr"
      },
      "outputs": [],
      "source": [
        "# now by holidays \n",
        "\n",
        "sns.catplot(x= 'Holiday' , y = 'Rented_Bike_Count' , data = df , kind = 'box' , height = 5.0 , aspect = 1.5)\n",
        "plt.title(\"count od rented bike acc to holidays \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHBNm0mDUIis"
      },
      "outputs": [],
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.pointplot(data=df,x='Hour',y='Rented_Bike_Count',hue='Seasons',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to seasons ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUmN39L-JeoX"
      },
      "outputs": [],
      "source": [
        "# create point plots with Rented Bike Count during different categorical features with respect of Hour\n",
        "for i in categorical_df.columns:\n",
        "  if i == 'Hour':\n",
        "    pass\n",
        "  else:\n",
        "    plt.figure(figsize=(20,10))\n",
        "    sns.pointplot(x=df[\"Hour\"],y=df['Rented_Bike_Count'],hue=df[i])\n",
        "    plt.title(f\"Rented Bike Count during different {i} with respect of Hour\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzPULhpGRluu"
      },
      "source": [
        "###### now focus on  numerical columns "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3DBe7s0QHOw"
      },
      "outputs": [],
      "source": [
        "# boxplot to check outliers in numerical columns \n",
        "n = 1\n",
        "plt.figure(figsize=(10,15))\n",
        "\n",
        "for col in numeric_df.columns:\n",
        "  plt.subplot(3,3,n)\n",
        "  n=n+1\n",
        "  sns.boxplot(df[col])\n",
        "  plt.title(col)\n",
        "  plt.xlabel(col)\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jSsBtDKOq7P"
      },
      "source": [
        "# since if we remove outlier from rainfall and snowfall column it will remove all of ur data so avoid them now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzbSU3ifs4Ew"
      },
      "outputs": [],
      "source": [
        "numeric_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzgerOGd2H7H"
      },
      "outputs": [],
      "source": [
        "# Heatmap of all variables against each other to see ther co-relations\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(data.corr(),annot=True,cmap='YlGnBu')\n",
        "plt.title(\"Numerical columns co-reltion heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvXVg2V0A8sN"
      },
      "outputs": [],
      "source": [
        "#printing displots to analyze the distribution of all numerical features\n",
        "numerical_columns=list(df.select_dtypes(['int64','float64']).columns)\n",
        "numerical_features=pd.Index(numerical_columns)\n",
        "for col in numerical_features:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  sns.distplot(x=df[col])\n",
        "  plt.xlabel(col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical vs.Rented_Bike_Count"
      ],
      "metadata": {
        "id": "gVMcrZGELpDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print the plot to analyze the relationship between \"Rented_Bike_Count\" and \"Temperature\" \n",
        "df.groupby('Temperature').mean()['Rented_Bike_Count'].plot(color='deeppink')"
      ],
      "metadata": {
        "id": "A-VrZUSILoee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above plot we see that people like to ride bikes when it is pretty hot around 25°C in average"
      ],
      "metadata": {
        "id": "UNu93UYzLzWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print the plot to analyze the relationship between \"Rented_Bike_Count\" and \"Dew_point_temperature\" \n",
        "df.groupby('Dew_point_temperature').mean()['Rented_Bike_Count'].plot(color='hotpink')"
      ],
      "metadata": {
        "id": "K8QmZiTeL0M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above plot of \"Dew_point_temperature' is almost same as the 'temperature' there is some similarity present we can check it in our next step."
      ],
      "metadata": {
        "id": "Ct1c9XNbL6N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#print the plot to analyze the relationship between \"Rented_Bike_Count\" and \"Solar_Radiation\" \n",
        "df.groupby('Solar_Radiation').mean()['Rented_Bike_Count'].plot(color=\"orchid\")"
      ],
      "metadata": {
        "id": "Zk7dKAZ8L7e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the above plot we see that, the amount of rented bikes is huge, when there is solar radiation, the counter of rents is around 1000"
      ],
      "metadata": {
        "id": "Mf5IIUG6MAlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print the plot to analyze the relationship between \"Rented_Bike_Count\" and \"Snowfall\" \n",
        "df.groupby('Snowfall').mean()['Rented_Bike_Count'].plot(color=\"violet\")"
      ],
      "metadata": {
        "id": "A9zPqi44MDZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the plot that, on the y-axis, the amount of rented bike is very low When we have more than 4 cm of snow, the bike rents is much lower"
      ],
      "metadata": {
        "id": "ap09IY-2MHgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print the plot to analyze the relationship between \"Rented_Bike_Count\" and \"Rainfall\" \n",
        "df.groupby('Rainfall').mean()['Rented_Bike_Count'].plot(color=\"lightpink\")"
      ],
      "metadata": {
        "id": "3cPkTGaAMIX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the above plot that even if it rains a lot the demand of of rent bikes is not decreasing, here for example even if we have 20 mm of rain there is a big peak of rented bikes"
      ],
      "metadata": {
        "id": "LhRjwFaxMNpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print the plot to analyze the relationship between \"Rented_Bike_Count\" and \"Wind_speed\" \n",
        "df.groupby('Wind_speed').mean()['Rented_Bike_Count'].plot(color=\"hotpink\")"
      ],
      "metadata": {
        "id": "AbRC7ZR2MO_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the above plot that the demand of rented bike is uniformly distribute despite of wind speed but when the speed of wind was 7 m/s then the demand of bike also increase that clearly means peoples love to ride bikes when its little windy."
      ],
      "metadata": {
        "id": "0x9Mz8tRMV6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvqgtwCUUNG-"
      },
      "outputs": [],
      "source": [
        "# take a look at vmaximum value of each column to get an idea about outlier\n",
        "\n",
        "print(df['Wind_speed'].max())\n",
        "print(df['Solar_Radiation'].max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6_ng3DmDxI0"
      },
      "outputs": [],
      "source": [
        "# according to upper bound and lower bound for iqr of each column \n",
        "\n",
        "df.loc[df['Solar_Radiation']>=2,'Solar_Radiation']= 2\n",
        "df.loc[df['Wind_speed' ]>=4,'Wind_speed']= 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAnTMHbpDxLi"
      },
      "outputs": [],
      "source": [
        "# and checking outliers again\n",
        " \n",
        "n = 1\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "for col in numeric_df.columns:\n",
        "  plt.subplot(3,3,n)\n",
        "  n=n+1\n",
        "  sns.boxplot(df[col],color='magenta')\n",
        "  plt.title(col)\n",
        "  plt.xlabel(col)\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iFOVv1VQHT2"
      },
      "outputs": [],
      "source": [
        "# now we need to treat this outlier and we can use caaping for it \n",
        "# according to upper bound and lower bound for iqr of each column \n",
        "\n",
        "\n",
        "df.loc[df['Solar_Radiation']>=2,'Solar_Radiation']= 2\n",
        "df.loc[df['Wind_speed' ]>=4,'Wind_speed']= 4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTv1XGlJ6bRX"
      },
      "source": [
        "Now we are moving ahead to find relation b/w our numerical independent column with rented bike column with help of regression plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WduBxvF3DxOk"
      },
      "outputs": [],
      "source": [
        "# to know relation with rented bike count with numerical columns\n",
        "n=1\n",
        "plt.figure(figsize=(15,15))\n",
        "for i in numeric_df.columns :\n",
        "  if i == 'Rented Bike Count':\n",
        "    pass\n",
        "  else:\n",
        "    plt.subplot(3,3,n )\n",
        "    n += 1\n",
        "    sns.regplot(df[i], df['Rented_Bike_Count'] , scatter_kws={\"color\": \"magenta\"}, line_kws={\"color\": \"red\"})\n",
        "    plt.title(f'Dependend variable and {i}')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1JrTvJdUNLM"
      },
      "outputs": [],
      "source": [
        "# now take a one look at these column max value to look at outlier problem\n",
        "\n",
        "print(df['Wind_speed'].max())\n",
        "print(df['Solar_Radiation'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDHDloVjUNOk"
      },
      "outputs": [],
      "source": [
        "# and again checking outliers again by emans of box plot \n",
        " \n",
        "n = 1\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "for col in numeric_df.columns:\n",
        "  plt.subplot(3,3,n)\n",
        "  n=n+1\n",
        "  sns.boxplot(df[col],color='darkorchid')\n",
        "  plt.title(col)\n",
        "  plt.xlabel(col)\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c9QGHrxa-ZM"
      },
      "outputs": [],
      "source": [
        "n = 1 \n",
        "for col in numeric_df.columns :\n",
        "  plt.figure(figsize = (50,20))\n",
        "  plt.subplot(3,3 ,n ) \n",
        "  n += 1 \n",
        "  sns.distplot(df[col])\n",
        "  feature = df[i]\n",
        "  plt.axvline(feature.mean(), color='black', linestyle = 'dashed' , linewidth=3)\n",
        "  plt.axvline(feature.median(), color='red', linestyle='dashed', linewidth=3)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression plot\n",
        "The regression plots in seaborn are primarily intended to add a visual guide that helps to emphasize patterns in a dataset during exploratory data analyses. Regression plots as the name suggests creates a regression line between 2 parameters and helps to visualize their linear relationships."
      ],
      "metadata": {
        "id": "IYFm3LnyKLmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the regression plot for all the numerical features\n",
        "for col in numerical_features:\n",
        "  fig,ax=plt.subplots(figsize=(10,6))\n",
        "  sns.regplot(x=df[col],y=df['Rented_Bike_Count'],scatter_kws={\"color\": 'coral'}, line_kws={\"color\": \"black\"})"
      ],
      "metadata": {
        "id": "_z1PWnNgHsUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7kxDdWYRih-"
      },
      "source": [
        "# Distplot plots we observe that some of our columns is right skewed and some are left skewed we have to remember this things when we apply algorithms\n",
        "#Right skewed columns are Rented Bike Count (Its also our Dependent variable), Wind_speed, Solar_Radiation, Rainfall(mm), Snowfall (cm) and \n",
        "# Left skewed columns ar# Visibility (10m), Dew point temperature(°C)\n",
        "# From Histogram we are coming to know that the features which are skewed, their mean and the median are also skewed, which was understood by looking at the graph that this would happen .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSXaoNWsRE8a"
      },
      "source": [
        "* ***The above graph shows that Rented Bike Count has moderate right skewness. Since the assumption of linear regression is that 'the distribution of dependent variable has to be normal', so we should perform some operation to normalize it.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SwJfN-Ka-fI"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (12 ,8))\n",
        "plt.xlabel(\"Rented  Bike Count\")\n",
        "plt.ylabel(\"Density of our dataset\") \n",
        "\n",
        "ax = sns.distplot(np.sqrt(df['Rented_Bike_Count']) , color = \"blue\")\n",
        "ax.axvline(np.sqrt(df['Rented_Bike_Count'].mean()) , color = 'black' , linestyle = 'dashed' , linewidth = 2.5)\n",
        "ax.axvline(np.sqrt(df['Rented_Bike_Count'].median()) , color = 'red' , linestyle = 'dashed' , linewidth = 2.5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX7SOwu1R42-"
      },
      "source": [
        "# Since we have generic rule of applying Square root for the skewed variable in order to make it normal .After applying Square root to the skewed Rented Bike Count, here we get almost normal distribution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#After applying sqrt on Rented Bike Count check wheater we still have outliers \n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.ylabel('Rented_Bike_Count')\n",
        "sns.boxplot(x=np.sqrt(df['Rented_Bike_Count']))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XKyeEFGSM_9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying Square root to the Rented Bike Count column, we find that there is no outliers present."
      ],
      "metadata": {
        "id": "fxzBgYDcNHGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking of Correlation between variables"
      ],
      "metadata": {
        "id": "DQisfQk_NK9x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG4KoTU_a-oc"
      },
      "outputs": [],
      "source": [
        " ## now corelation b/w the  dependent varaiables with rented bike count\n",
        "\n",
        "df.corr()['Rented_Bike_Count']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEjKNB7hSIl7"
      },
      "source": [
        "we observed smilar things in regression plot also where some feature are negatively correlated and some positively correalted with depend var "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plot the Correlation matrix\n",
        "plt.figure(figsize=(20,8))\n",
        "correlation=df.corr()\n",
        "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
        "sns.heatmap((correlation),mask=mask, annot=True,cmap='coolwarm')"
      ],
      "metadata": {
        "id": "OHSDiLNNSl1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CogkvkJRSSNb"
      },
      "source": [
        "From the above correlation heatmap, We see that there is a positive correlation between columns 'Temperature' and 'Dew point temperature' i.e 0.91 so even if we drop this column then it dont affects the outcome of our analysis. And they have the same variations.. so we can drop the column 'Dew point temperature(°C)'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH_dHv4sWFcE"
      },
      "outputs": [],
      "source": [
        "# dropping dew point column\n",
        "df.drop(['Dew_point_temperature'] , axis = 1 , inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# one hot encoding"
      ],
      "metadata": {
        "id": "3zmfer-hUEAt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoWM6P14kClf"
      },
      "source": [
        "###### one hot encoding to convert categorical into numerical columns for better alaysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9KOZ4hVkBdP"
      },
      "outputs": [],
      "source": [
        "df_enc = df.copy()\n",
        "\n",
        "def one_hot_encoding(data , column ) :\n",
        "  data = pd.concat([data , pd.get_dummies(data[column] , prefix = column , drop_first = True)] , axis = 1)\n",
        "  data = data.drop([column], axis =1 )\n",
        "  return data\n",
        "\n",
        "for col in categorical_df :\n",
        "  df_enc = one_hot_encoding(df_enc , col )\n",
        "df_enc.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd7llwg1kBgg"
      },
      "outputs": [],
      "source": [
        "# now multicolinearity with te help of vif\n",
        "# make vif calculate function\n",
        "\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVpj_GGdnsKT"
      },
      "outputs": [],
      "source": [
        "# now cal vif our feature columns \n",
        "calc_vif(df_enc[[i for i in df_enc.describe().columns if i not in ['Rented_Bike_Count',]]] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ-IWFBtnsPy"
      },
      "outputs": [],
      "source": [
        "# now we will seprate our datasets dependent and indepent and dependent columns \n",
        "\n",
        "X = df_enc.drop(columns = ['Rented_Bike_Count'] , axis  = 1)\n",
        "Y = np.sqrt(df_enc['Rented_Bike_Count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4K0oVUHnsSU"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiPTRpsNnsU6"
      },
      "outputs": [],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rykds-5wp9u0"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Test split for regression"
      ],
      "metadata": {
        "id": "m-klVXnaUXZA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jGe0mHZnsXQ"
      },
      "outputs": [],
      "source": [
        "# now test, train and split database \n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train , X_test , Y_train , Y_test = train_test_split(X , Y , test_size = 0.2 , random_state = 1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HhqM46QZLXt"
      },
      "outputs": [],
      "source": [
        "df_enc.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmSnW2HO0LSH"
      },
      "source": [
        "# now we will go toward model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMfnNrwn1Gfk"
      },
      "source": [
        "Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2vpHj700ORw"
      },
      "outputs": [],
      "source": [
        "# import linear  regression and make its object\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg= LinearRegression().fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpqI6RsE4m04"
      },
      "outputs": [],
      "source": [
        "# accuracy score on training dataset\n",
        "reg.score(X_train , Y_train )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67e4rAA0rEe6"
      },
      "outputs": [],
      "source": [
        "#check the coefficeint\n",
        "reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJrJxbTprHmz"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "Y_train_pred=reg.predict(X_train)\n",
        "Y_test_pred=reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_NaFWxXcctU"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "#Score matrics on train data\n",
        "print(f\"Linear regression training set metrics:\")\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "MSE_lr1 = ( mean_squared_error(Y_train, Y_train_pred))\n",
        "print(\"MSE\", MSE_lr1)\n",
        "\n",
        "MAE_lr1 = (mean_absolute_error(Y_train, Y_train_pred))\n",
        "print(\"MAE\", MAE_lr1)\n",
        "\n",
        "RMSE_lr1 = (np.sqrt(mean_squared_error(Y_train, Y_train_pred)))\n",
        "print(\"RMSE\", RMSE_lr1)\n",
        "\n",
        "R2_score_lr1 = r2_score(Y_train, Y_train_pred)\n",
        "print(\"R2_score\", R2_score_lr1)\n",
        "\n",
        "Adjusted_r2_lrl = (1-(1-r2_score(Y_train, Y_train_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted_r2\" , Adjusted_r2_lrl)\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjr2JSSPtJ36"
      },
      "outputs": [],
      "source": [
        "#Score matrics on test data\n",
        "print(f\"Linear regression testing set metrics:\")\n",
        "\n",
        "MSE_lr2 = ( mean_squared_error(Y_test, Y_test_pred))\n",
        "print(\"MSE\", MSE_lr2)\n",
        "\n",
        "MAE_lr2 = (mean_absolute_error(Y_test, Y_test_pred))\n",
        "print(\"MAE\", MAE_lr2)\n",
        "\n",
        "RMSE_lr2 = (np.sqrt(mean_squared_error(Y_test, Y_test_pred)))\n",
        "print(\"RMSE\", RMSE_lr2)\n",
        "\n",
        "R2_score_lr2 = r2_score(Y_test, Y_test_pred)\n",
        "print(\"R2_score\", R2_score_lr2)\n",
        "\n",
        "Adjusted_r2_lr2 = 1-((1-R2_score_lr2)* (X_test.shape[0]-1)/ (X_test.shape[0]-1 -(X_test.shape[1])))\n",
        "print(\"Adjusted_r2\" , Adjusted_r2_lr2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKCLwHTlni7B"
      },
      "outputs": [],
      "source": [
        "reg.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59QR-DuxsLep"
      },
      "source": [
        "\n",
        "The r2_score for the test set is 0.78. This means our linear model is performing well on the data. Let us try to visualize our residuals and see if there is heteroscedasticity(unequal variance or scatter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMt75wD_uc66"
      },
      "outputs": [],
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((Y_test_pred),(Y_test)-(Y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV-jI2ol4gbT"
      },
      "outputs": [],
      "source": [
        "#visualization\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot((Y_test_pred), color = 'green')\n",
        "plt.plot(np.array(Y_test), color = 'yellow')\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.title(\"Linear regression\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Totk7SI93yBi"
      },
      "outputs": [],
      "source": [
        "# creating a dict to concat linear training and test data score metrics\n",
        "# storing the train set metrics value in a dict for later comparison\n",
        "dict1={'Model':'Linear regression ',\n",
        "       'MAE':round((MAE_lr1),2),\n",
        "       'MSE':round((MSE_lr1),2),\n",
        "       'RMSE':round((RMSE_lr1),2),\n",
        "       'R2_score':round((R2_score_lr1),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_lrl),2)\n",
        "       }\n",
        "lr_dict1 = pd.DataFrame(dict1,index=[1])\n",
        "training_df=pd.DataFrame(dict1,index=[1])\n",
        "\n",
        "# storing the test set metrics value in a dict for later comparison\n",
        "dict2={'Model':'Linear regression ',\n",
        "       'MAE':round((MAE_lr2),2),\n",
        "       'MSE':round((MSE_lr2),2),\n",
        "       'RMSE':round((RMSE_lr2),2),\n",
        "       'R2_score':round((R2_score_lr2),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_lr2 ),2)\n",
        "       }\n",
        "lr_dict2 = pd.DataFrame(dict2,index=[1])\n",
        "test_df=pd.DataFrame(dict2,index=[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nOeZQaslWvf"
      },
      "outputs": [],
      "source": [
        "# linear regression score for train and test data\n",
        "result=pd.concat([lr_dict1,lr_dict2],keys=['Training set','Test set'])\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv1fOFA_x4lQ"
      },
      "source": [
        "# LASSO REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2Bq_Vm6lahX"
      },
      "outputs": [],
      "source": [
        "# Create an instance of Lasso Regression implementation\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=5)\n",
        "# Fit the Lasso model\n",
        "lasso_regressor.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAe4K6VFkCR-"
      },
      "outputs": [],
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8U5eZT8kLAk"
      },
      "outputs": [],
      "source": [
        "lasso = Lasso(alpha=0.001, max_iter=1000)\n",
        "lasso.fit(X_train, Y_train)\n",
        "Y_pred_train_lasso = lasso.predict(X_train)                 \n",
        "Y_pred_test_lasso = lasso.predict(X_test)                     \n",
        "print(Y_pred_train_lasso)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPHwmy3AjCLy"
      },
      "outputs": [],
      "source": [
        "#Score matrics on train data\n",
        "print(f\"Lasso training set metrics:\")\n",
        "\n",
        "MSE_lasso1 = (mean_squared_error(Y_train, Y_pred_train_lasso))\n",
        "print(\"MSE\", MSE_lasso1)\n",
        "\n",
        "MAE_lasso1 = (mean_absolute_error(Y_train, Y_pred_train_lasso))\n",
        "print(\"MAE\", MAE_lasso1)\n",
        "\n",
        "RMSE_lasso1 = (np.sqrt(mean_squared_error(Y_train, Y_pred_train_lasso)))\n",
        "print(\"RMSE\", RMSE_lasso1)\n",
        "\n",
        "R2_lasso1 = r2_score(Y_train, Y_pred_train_lasso)\n",
        "print('R2', R2_lasso1)\n",
        "\n",
        "Adjusted_r2_lasso1 = 1-(1-(R2_lasso1)* (X_train.shape[0]-1)/ (X_train.shape[0]-1 -(X_train.shape[1])))\n",
        "print(\"Adjusted_R2\", Adjusted_r2_lasso1)\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUgpPkKakdtU"
      },
      "outputs": [],
      "source": [
        "#Score matrics on test data\n",
        "print(f\"Lasso test set metrics:\")\n",
        "\n",
        "MSE_lasso2 = (mean_squared_error(Y_test, Y_pred_test_lasso))\n",
        "print(\"MSE\", MSE_lasso2)\n",
        "\n",
        "MAE_lasso2 = (mean_absolute_error(Y_test, Y_pred_test_lasso))\n",
        "print(\"MAE\", MAE_lasso2)\n",
        "\n",
        "RMSE_lasso2 = (np.sqrt(mean_squared_error(Y_test, Y_pred_test_lasso)))\n",
        "print(\"RMSE\", RMSE_lasso2)\n",
        "\n",
        "R2_lasso2 = r2_score(Y_test, Y_pred_test_lasso)\n",
        "print('R2', R2_lasso2)\n",
        "\n",
        "Adjusted_r2_lasso2 = 1-(1-(R2_lasso2)* (X_test.shape[0]-1)/ (X_test.shape[0]-1 -(X_test.shape[1])))\n",
        "print(\"Adjusted_R2\", Adjusted_r2_lasso2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rhm_jnFyECM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_l= mean_squared_error((Y_train), (Y_pred_train_lasso))\n",
        "print(\"MSE :\",MSE_l)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_l=np.sqrt(MSE_l)\n",
        "print(\"RMSE :\",RMSE_l)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_l= mean_absolute_error(Y_train, Y_pred_train_lasso)\n",
        "print(\"MAE :\",MAE_l)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_l= r2_score(Y_train, Y_pred_train_lasso)\n",
        "print(\"R2 :\",r2_l)\n",
        "Adjusted_R2_l = (1-(1-r2_score(Y_train, Y_pred_train_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(Y_train, Y_pred_train_lasso))**((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRlB0vGDzH5o"
      },
      "outputs": [],
      "source": [
        "# creating a dict to concat lasso training and test data score metrics\n",
        "# storing the Train set metrics value in a dict3 for later comparison\n",
        "dict3={'Model':'Lasso regression ',\n",
        "       'MAE':round((MAE_lasso1),2),\n",
        "       'MSE':round((MSE_lasso1),2),\n",
        "       'RMSE':round((RMSE_lasso1),2),\n",
        "       'R2_score':round((R2_lasso1),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_lasso1),2)\n",
        "       }\n",
        "lasso_dict3 =pd.DataFrame(dict3,index=[1])\n",
        "training_df=training_df.append(dict3,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sp_4lHCo2UlP"
      },
      "outputs": [],
      "source": [
        "# storing the test set metrics value in a dict4 for later comparison\n",
        "dict4={'Model':'Lasso regression ',\n",
        "       'MAE':round((MAE_lasso2),2),\n",
        "       'MSE':round((MSE_lasso2),2),\n",
        "       'RMSE':round((RMSE_lasso2),2),\n",
        "       'R2_score':round((R2_lasso2),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_lasso2 ),2)\n",
        "       }\n",
        "lasso_dict4 =pd.DataFrame(dict4,index=[1])\n",
        "test_df=test_df.append(dict4,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0RdhuewzxEr"
      },
      "outputs": [],
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(np.array(Y_pred_test_lasso))\n",
        "plt.plot(np.array((Y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.title('Regularization: Lasso')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcDE8QlDz10o"
      },
      "outputs": [],
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((Y_pred_test_lasso),(Y_test-Y_pred_test_lasso))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8nK52Pa7zBp"
      },
      "outputs": [],
      "source": [
        "result=pd.concat([lasso_dict3,lasso_dict4],keys=['Training set','Test set'])\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36ZSa8hd0Hp8"
      },
      "source": [
        "RIDGE REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgI4TiaSnPZn"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge= Ridge(alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuXGa4il0K-Y"
      },
      "outputs": [],
      "source": [
        "#FIT THE MODEL\n",
        "ridge.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1kMUtav0Mmr"
      },
      "outputs": [],
      "source": [
        "#check the score\n",
        "ridge.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dni0BYcm0O-i"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_ridge=ridge.predict(X_train)\n",
        "y_pred_test_ridge=ridge.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgJzVG1K0T1-"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_r= mean_squared_error((Y_train), (y_pred_train_ridge))\n",
        "print(\"MSE :\",MSE_r)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r=np.sqrt(MSE_r)\n",
        "print(\"RMSE :\",RMSE_r)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r= mean_absolute_error(Y_train, y_pred_train_ridge)\n",
        "print(\"MAE :\",MAE_r)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r= r2_score(Y_train, y_pred_train_ridge)\n",
        "print(\"R2 :\",r2_r)\n",
        "Adjusted_R2_r=(1-(1-r2_score(Y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(Y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88H_zMGMntT4"
      },
      "outputs": [],
      "source": [
        "#Score matrics on test data\n",
        "print(f\"Ridge Regression: evaluation metrics on the testing set:\")\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score      \n",
        "MSE_ridge2 = (mean_squared_error(Y_test, y_pred_test_ridge))\n",
        "print('MSE', MSE_ridge2)\n",
        "MAE_ridge2 =  (mean_absolute_error(Y_train, y_pred_train_ridge))\n",
        "print('MAE', MAE_ridge2)\n",
        "RMSE_ridge2 =  np.sqrt(mean_squared_error(Y_test, y_pred_test_ridge))\n",
        "print(\"RMSE\", RMSE_ridge2)\n",
        "R2_score_ridge2 = r2_score(Y_test,y_pred_test_ridge)\n",
        "print(\"R2_score\", R2_score_ridge2)\n",
        "Adjusted_r2_ridge2 = 1-(1-(R2_score_ridge2)* (X_test.shape[0]-1)/ (X_test.shape[0]-1 -(X_test.shape[1])))\n",
        "print(\"Adjusted_R2\", Adjusted_r2_ridge2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IknZjGME0pnz"
      },
      "outputs": [],
      "source": [
        "# creating a dict to concat ridge training and test data score metrics\n",
        "# storing the Train set metrics value in a dict5 for later comparison\n",
        "dict5={'Model':'Ridge regression ',\n",
        "       'MAE':round((MAE_r),2),\n",
        "       'MSE':round((MSE_r),2),\n",
        "       'RMSE':round((RMSE_r),2),\n",
        "       'R2_score':round((r2_r),2),\n",
        "       'Adjusted R2':round((Adjusted_R2_r),2)\n",
        "       }\n",
        "ridge_dict5 =pd.DataFrame(dict5,index=[1])\n",
        "training_df=training_df.append(dict5,ignore_index=True)\n",
        "\n",
        "# storing the test set metrics value in a dict6 for later comparison\n",
        "dict6={'Model':'Ridge regression ',\n",
        "       'MAE':round((MAE_ridge2),2),\n",
        "       'MSE':round((MSE_ridge2),2),\n",
        "       'RMSE':round((RMSE_ridge2),2),\n",
        "       'R2_score':round((R2_score_ridge2),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_ridge2 ),2)\n",
        "       }\n",
        "ridge_dict6 =pd.DataFrame(dict6,index=[1])\n",
        "test_df=test_df.append(dict6,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-P2JoOW0xLP"
      },
      "outputs": [],
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot((y_pred_test_ridge))\n",
        "plt.plot((np.array(Y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.title('Regularization: Ridge')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dRxKzo10zKA"
      },
      "outputs": [],
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_test_ridge),(Y_test)-(y_pred_test_ridge))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySpweWk29pzm"
      },
      "outputs": [],
      "source": [
        "result=pd.concat([ridge_dict5,ridge_dict6],keys=['Training set','Test set'])\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-QkZxZhpgBS"
      },
      "source": [
        "# ELASTIC NET REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1dx6J8lpfs9"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import ElasticNet\n",
        "#a * L1 + b * L2\n",
        "#alpha = a + b and l1_ratio = a / (a + b)\n",
        "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zS32fpbpjKd"
      },
      "outputs": [],
      "source": [
        "#FIT THE MODEL\n",
        "elasticnet.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJrIaH4Rpn8S"
      },
      "outputs": [],
      "source": [
        "#check the score\n",
        "elasticnet.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RXgS5pUptYw"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_en=elasticnet.predict(X_train)\n",
        "y_pred_test_en=elasticnet.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv6OvBr7qbbH"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e= mean_squared_error((Y_train), (y_pred_train_en))\n",
        "print(\"MSE :\",MSE_e)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e=np.sqrt(MSE_e)\n",
        "print(\"RMSE :\",RMSE_e)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e= mean_absolute_error(Y_train, y_pred_train_en)\n",
        "print(\"MAE :\",MAE_e)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e= r2_score(Y_train, y_pred_train_en)\n",
        "print(\"R2 :\",r2_e)\n",
        "\n",
        "Adjusted_R2_e=(1-(1-r2_score(Y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(Y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PpDCbnttiyc"
      },
      "outputs": [],
      "source": [
        "#Score matrics on test data\n",
        "print(f\"Ridge Regression: evaluation metrics on the testing set:\")\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score      \n",
        "MSE_e = (mean_squared_error(Y_test, y_pred_test_en))\n",
        "print('MSE:', MSE_e)\n",
        "\n",
        "MAE_ridge2 =  (mean_absolute_error(Y_train, y_pred_train_en))\n",
        "print('MAE', MAE_e)\n",
        "\n",
        "RMSE_ridge2 =  np.sqrt(mean_squared_error(Y_test, y_pred_test_en))\n",
        "print(\"RMSE\", RMSE_e)\n",
        "\n",
        "R2_e = r2_score(Y_test,y_pred_test_en)\n",
        "print(\"R2_score\", R2_e)\n",
        "\n",
        "Adjusted_r2_e = 1-(1-(r2_e)* (X_test.shape[0]-1)/ (X_test.shape[0]-1 -(X_test.shape[1])))\n",
        "print(\"Adjusted_R2:\", Adjusted_r2_e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq5g-YY7rHT4"
      },
      "outputs": [],
      "source": [
        " #storing the test set metrics value in a dataframe for later comparison\n",
        "dict7={'Model':'Elastic net regression Test',\n",
        "       'MAE':round((MAE_e),3),\n",
        "       'MSE':round((MSE_e),3),\n",
        "       'RMSE':round((RMSE_e),3),\n",
        "       'R2_score':round((r2_e),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_e ),2)}\n",
        "\n",
        "e_dict7 =pd.DataFrame(dict7,index=[1])\n",
        "training_df=training_df.append(dict7,ignore_index=True)\n",
        "\n",
        " #storing the test set metrics value in a dict6 for later comparison\n",
        "dict8={'Model':'Elastic net regression Test',\n",
        "       'MAE':round((MAE_e),3),\n",
        "       'MSE':round((MSE_e),3),\n",
        "       'RMSE':round((RMSE_e),3),\n",
        "       'R2_score':round((r2_e),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_e ),2)\n",
        "       }\n",
        "e_dict8 =pd.DataFrame(dict8,index=[1])\n",
        "test_df=test_df.append(dict8,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzMVPEPiroNk"
      },
      "outputs": [],
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(np.array(y_pred_test_en))\n",
        "plt.plot((np.array(Y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.title('Regularization: Elastic net regression ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lq-Sc2A7rxAr"
      },
      "outputs": [],
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_test_en),(Y_test)-(y_pred_test_en))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUK0SRZdsHWm"
      },
      "outputs": [],
      "source": [
        "result=pd.concat([e_dict7,e_dict8],keys=['Training set','Test set'])\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT3lshmCj3F-"
      },
      "source": [
        "## **Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Baz7STsetSr7"
      },
      "outputs": [],
      "source": [
        "# importing deciion tree regressor\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN-jA5nFvcSv"
      },
      "outputs": [],
      "source": [
        "# storing object for decision tree regresssor with max depth 15\n",
        "dt_model = DecisionTreeRegressor(max_depth = 12)\n",
        "# calling dt_model to train,fit and evalution of decision tree model\n",
        "dt_model.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QEOhf2nvg1I"
      },
      "outputs": [],
      "source": [
        "#Y_pred for traning and testing dataset\n",
        "Y_pred1_dt = dt_model.predict(X_train)\n",
        "Y_pred2_dt = dt_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHHvJHnFvi2m"
      },
      "outputs": [],
      "source": [
        "# decision tree score\n",
        "dt_model.score(X_train , Y_train )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCyIo-yHvmyu"
      },
      "outputs": [],
      "source": [
        "#Score matrics on train data\n",
        "print(f\"Decision Tree: evaluation metrics on the training set:\")\n",
        "#importing matrics for training data\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score   \n",
        "MSE_dt1 = mean_squared_error(Y_train, Y_pred1_dt)\n",
        "print(\"MSE\", MSE_dt1)\n",
        "MAE_dt1 = mean_absolute_error(Y_train, Y_pred1_dt)\n",
        "print('MAE', MAE_dt1)\n",
        "RMSE_dt1 =  np.sqrt(mean_squared_error(Y_train, Y_pred1_dt))\n",
        "print(\"RMSE\", RMSE_dt1)\n",
        "R2_score_dt1 = r2_score(Y_train, Y_pred1_dt)\n",
        "print(\"R2_score\", R2_score_dt1)\n",
        "Adjusted_r2_dt1 = 1-(1-(R2_score_dt1)* (X_train.shape[0]-1)/ (X_train.shape[0]-1 -(X_train.shape[1])))\n",
        "print(\"Adjusted_R2\", Adjusted_r2_dt1)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KnQ3oenvpV3"
      },
      "outputs": [],
      "source": [
        "#Score matrics on test data\n",
        "print(f\"Decision Tree: evaluation metrics on the testing set:\")\n",
        "#importing matrics for training data\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score   \n",
        "MSE_dt2 = mean_squared_error(Y_test, Y_pred2_dt)\n",
        "print(\"MSE\", MSE_dt2)\n",
        "MAE_dt2 = mean_absolute_error(Y_test, Y_pred2_dt)\n",
        "print('MAE', MAE_dt2)\n",
        "RMSE_dt2 =  np.sqrt(mean_squared_error(Y_test, Y_pred2_dt))\n",
        "print(\"RMSE\", RMSE_dt2)\n",
        "R2_score_dt2 = r2_score(Y_test, Y_pred2_dt)\n",
        "print(\"R2_score\", R2_score_dt2)\n",
        "Adjusted_r2_dt2 = 1-(1-(R2_score_dt2)* (X_train.shape[0]-1)/ (X_train.shape[0]-1 -(X_train.shape[1])))\n",
        "print(\"Adjusted_R2\", Adjusted_r2_dt2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjoPvEaADEKS"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot((Y_pred2_dt), color = 'k')\n",
        "plt.plot(np.array(Y_test), color = 'c')\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.title('Decision Tree')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpHAYAw7v3jq"
      },
      "outputs": [],
      "source": [
        "# creating a dict to concat ridge training and test data score metrics\n",
        "# storing the Train set metrics value in a dict7 for later comparison\n",
        "dict9={'Model':'Decision Tree ',\n",
        "       'MAE':round((MAE_dt1),2),\n",
        "       'MSE':round((MSE_dt1),2),\n",
        "       'RMSE':round((RMSE_dt1),2),\n",
        "       'R2_score':round((R2_score_dt1),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_dt1),2)\n",
        "       }\n",
        "dt_dict9 =pd.DataFrame(dict9,index=[1])\n",
        "training_df=training_df.append(dict9,ignore_index=True)\n",
        "\n",
        "# storing the test set metrics value in a dict8 for later comparison\n",
        "dict10={'Model':'Decision Tree',\n",
        "       'MAE':round((MAE_dt2),2),\n",
        "       'MSE':round((MSE_dt2),2),\n",
        "       'RMSE':round((RMSE_ridge2),2),\n",
        "       'R2_score':round((R2_score_ridge2),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_ridge2 ),2)\n",
        "       }\n",
        "dt_dict10 =pd.DataFrame(dict10,index=[1])\n",
        "test_df=test_df.append(dict10,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzLkqbf3v-j6"
      },
      "outputs": [],
      "source": [
        "result=pd.concat([dt_dict9,dt_dict10],keys=['Training set','Test set'])\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mtP6fn1ge7r"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQXw4cg7v-6D"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K51RuviE9_m4"
      },
      "outputs": [],
      "source": [
        "# creating param dict to check random forest with diffirent value of parameter through gridsearch\n",
        "n_estimators=[60,80,100]\n",
        "max_depth=[15,20]\n",
        "max_leaf_nodes=[60,80]\n",
        "max_features = [0.2, 0.5, 0.8 ]\n",
        "params = {'n_estimators':n_estimators,'max_depth':max_depth ,'max_leaf_nodes':max_leaf_nodes, \"max_features\" : max_features }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5XI1qvi522v"
      },
      "outputs": [],
      "source": [
        "# creating rf_grid model to run rf model with gridsearch\n",
        "rf_grid= GridSearchCV(rf,param_grid=params,verbose=0, n_jobs = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ5cxMJ2wNOf"
      },
      "outputs": [],
      "source": [
        "rf_grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH58_08wwOrO"
      },
      "outputs": [],
      "source": [
        "# to see best prameter\n",
        "rf_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO4gawv_wQB6"
      },
      "outputs": [],
      "source": [
        "rf_grid.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZtypabAwSjc"
      },
      "outputs": [],
      "source": [
        "# random forest with best parameter\n",
        "rf = RandomForestRegressor(max_depth = 20, max_leaf_nodes = 80, n_estimators =  80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwXnnT2LwYr_"
      },
      "outputs": [],
      "source": [
        "# fitting x-train and y-train\n",
        "rf.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7YcVvcRwaGc"
      },
      "outputs": [],
      "source": [
        "# predictions and score\n",
        "rf_y_pred1 = rf.predict(X_train)\n",
        "rf_y_pred2 = rf.predict(X_test)\n",
        "rf.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HdA0gKPbvjr"
      },
      "outputs": [],
      "source": [
        "#Score matrics on train data\n",
        "print(f\"Random Forest: evaluation metrics on the training set:\")\n",
        "#importing matrics for training data\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "MSE_rf1 = mean_squared_error(Y_train, rf_y_pred1)       \n",
        "print(\"MSE\", MSE_rf1)\n",
        "MAE_rf1 = mean_absolute_error(Y_train, rf_y_pred1)\n",
        "print('MAE', MAE_rf1)\n",
        "RSME_rf1 = np.sqrt(mean_squared_error(Y_train, rf_y_pred1))\n",
        "print(\"RMSE\", RSME_rf1)\n",
        "R2_score_rf1 = r2_score(Y_train, rf_y_pred1)\n",
        "print(\"R2score\", R2_score_rf1)\n",
        "Adjusted_r2_rf1 = 1-(1-(R2_score_rf1)* (X_train.shape[0]-1)/ (X_train.shape[0]-1 -(X_train.shape[1])))\n",
        "print(\"Adjusted_R2\", Adjusted_r2_rf1)\n",
        "print()\n",
        "\n",
        "\n",
        "#Score matrics on train data\n",
        "print(f\"Random Forest: evaluation metrics on the testing set:\")\n",
        "MSE_rf2 = mean_squared_error(Y_test, rf_y_pred2)       \n",
        "print(\"MSE\", MSE_rf2)\n",
        "MAE_rf2 = mean_absolute_error(Y_test, rf_y_pred2)\n",
        "print('MAE', MAE_rf2)\n",
        "RSME_rf2 = np.sqrt(mean_squared_error(Y_test, rf_y_pred2))\n",
        "print(\"RMSE\", RSME_rf2)\n",
        "R2_score_rf2 = r2_score(Y_test, rf_y_pred2)\n",
        "print(\"R2score\", R2_score_rf2)\n",
        "Adjusted_r2_rf2 = 1-(1-(R2_score_rf2)* (X_test.shape[0]-1)/ (X_test.shape[0]-1 -(X_test.shape[1])))\n",
        "print(\"Adjusted_R2\", Adjusted_r2_rf2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ssgS9yD0X3n"
      },
      "outputs": [],
      "source": [
        "# creating a dict to concat ridge training and test data score metrics\n",
        "# storing the Train set metrics value in a dict9 for later comparison\n",
        "dict9={'Model':'Random Forest ',\n",
        "       'MAE':round((MAE_rf1),2),\n",
        "       'MSE':round((MSE_rf1),2),\n",
        "       'RMSE':round((RSME_rf1),2),\n",
        "       'R2_score':round((R2_score_rf1),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_rf1),2)\n",
        "       }\n",
        "training_df=training_df.append(dict9,ignore_index=True)\n",
        "rf_dict9 =pd.DataFrame(dict9,index=[1])\n",
        "\n",
        "# storing the test set metrics value in a dict10 for later comparison\n",
        "dict10={'Model':'Random Forest ',\n",
        "       'MAE':round((MAE_rf2),2),\n",
        "       'MSE':round((MSE_rf2),2),\n",
        "       'RMSE':round((RSME_rf2),2),\n",
        "       'R2_score':round((R2_score_rf2),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_rf2 ),2)\n",
        "       }\n",
        "test_df=test_df.append(dict10,ignore_index=True)\n",
        "rf_dict10 =pd.DataFrame(dict10,index=[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpLKqqVAFFA0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot((rf_y_pred2), color = 'k')\n",
        "plt.plot(np.array(Y_test), color = 'c')\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.title('Random Forest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFSeHimK_CQl"
      },
      "outputs": [],
      "source": [
        "result=pd.concat([rf_dict9,rf_dict10],keys=['Training set','Test set'])\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyQfehPO0jy_"
      },
      "outputs": [],
      "source": [
        "rf.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luQJ_Pwq6HTe"
      },
      "outputs": [],
      "source": [
        "importances = rf.feature_importances_\n",
        "\n",
        "importance_dict = {'Feature' : list(X_train.columns),\n",
        "                   'Feature Importance' : importances}\n",
        "\n",
        "importance_df = pd.DataFrame(importance_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YanipHfd6PMO"
      },
      "outputs": [],
      "source": [
        "importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78UZbKi16ogK"
      },
      "outputs": [],
      "source": [
        "importance_df.sort_values(by=['Feature Importance'],ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2Xu5JGp6sNm"
      },
      "outputs": [],
      "source": [
        "#FIT THE MODEL\n",
        "rf.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZvczTl560Kj"
      },
      "outputs": [],
      "source": [
        "features = X_train.columns\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmjEpkQE65A3"
      },
      "outputs": [],
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(10,15))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='blue', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "917ZBgu4w9sA"
      },
      "source": [
        "# GRADIENT BOOSTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDl01PlzwrgA"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "# Create an instance of the GradientBoostingRegressor\n",
        "gb =GradientBoostingRegressor()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEteOC8xOti"
      },
      "outputs": [],
      "source": [
        "# creating param dict to check diffirent value of parameter\n",
        "n_estimators=[100,150, 180]\n",
        "max_depth=[5, 8, 10, 12]\n",
        "\n",
        "params = {'n_estimators':n_estimators,'max_depth':max_depth}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBQ1UO-txQHj"
      },
      "outputs": [],
      "source": [
        "#grid search for gradient bossting\n",
        "gb_grid= GridSearchCV(gb,param_grid=params,verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdrweu6sxWiE"
      },
      "outputs": [],
      "source": [
        "# fitting x-train and y-train\n",
        "gb_grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwEXA7NwxXz2"
      },
      "outputs": [],
      "source": [
        "gb_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHa3YIoJxZ7a"
      },
      "outputs": [],
      "source": [
        "gb_grid.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05PQJXIPxcZ6"
      },
      "outputs": [],
      "source": [
        "#creating model of Gradient Boosting\n",
        "gb =GradientBoostingRegressor(max_depth = 8, n_estimators = 180)\n",
        "gb.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iOcVwduxcuM"
      },
      "outputs": [],
      "source": [
        "# predictions and score\n",
        "gb_y_pred1 = gb.predict(X_train)\n",
        "gb_y_pred2 = gb.predict(X_test)\n",
        "gb.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVJUaRVnxoXK"
      },
      "outputs": [],
      "source": [
        "#Score matrics on train data\n",
        "print(f\"Gradient Boosting: evaluation metrics on the training set:\")\n",
        "#importing matrics for training data\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "MSE_gb1 = mean_squared_error(Y_train, gb_y_pred1)       \n",
        "print(\"MSE\", MSE_gb1)\n",
        "MAE_gb1 = mean_absolute_error(Y_train, gb_y_pred1)\n",
        "print('MAE', MAE_gb1)\n",
        "RSME_gb1 = np.sqrt(mean_squared_error(Y_train, gb_y_pred1))\n",
        "print(\"RMSE\", RSME_gb1)\n",
        "R2_score_gb1 = r2_score(Y_train, gb_y_pred1)\n",
        "print(\"R2score\", R2_score_gb1)\n",
        "Adjusted_r2_gb1 = 1-(1-(R2_score_gb1)* (X_train.shape[0]-1)/ (X_train.shape[0]-1 -(X_train.shape[1])))\n",
        "print(\"Adjusted_R2\", Adjusted_r2_gb1)\n",
        "print()\n",
        "\n",
        "\n",
        "#Score matrics on train data\n",
        "print(f\"Gradient Boosting: evaluation metrics on the testing set:\")\n",
        "MSE_gb2 = mean_squared_error(Y_test, gb_y_pred2)       \n",
        "print(\"MSE\", MSE_gb2)\n",
        "MAE_gb2 = mean_absolute_error(Y_test, gb_y_pred2)\n",
        "print('MAE', MAE_gb2)\n",
        "RSME_gb2 = np.sqrt(mean_squared_error(Y_test, gb_y_pred2))\n",
        "print(\"RMSE\", RSME_gb2)\n",
        "R2_score_gb2 = r2_score(Y_test, gb_y_pred2)\n",
        "print(\"R2score\", R2_score_gb2)\n",
        "Adjusted_r2_gb2 = 1-(1-(R2_score_gb2)* (X_test.shape[0]-1)/ (X_test.shape[0]-1 -(X_test.shape[1])))\n",
        "print(\"Adjusted_R2\", Adjusted_r2_gb2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V95a6gvPzY_U"
      },
      "outputs": [],
      "source": [
        "# creating a dict to concat ridge training and test data score metrics\n",
        "# storing the Train set metrics value in a dict11 for later comparison\n",
        "dict11={'Model':'Gradient Boosting',\n",
        "       'MAE':round((MAE_gb1),2),\n",
        "       'MSE':round((MSE_gb1),2),\n",
        "       'RMSE':round((RSME_gb1),2),\n",
        "       'R2_score':round((R2_score_gb1),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_gb1),2)\n",
        "       }\n",
        "training_df=training_df.append(dict11,ignore_index=True)\n",
        "gb_dict11 =pd.DataFrame(dict11,index=[1])\n",
        "\n",
        "# storing the test set metrics value in a dict12 for later comparison\n",
        "dict12={'Model':'Gradient Boosting',\n",
        "       'MAE':round((MAE_gb2),2),\n",
        "       'MSE':round((MSE_gb2),2),\n",
        "       'RMSE':round((RSME_gb2),2),\n",
        "       'R2_score':round((R2_score_gb2),2),\n",
        "       'Adjusted R2':round((Adjusted_r2_gb2 ),2)\n",
        "       }\n",
        "test_df=test_df.append(dict12,ignore_index=True)\n",
        "gb_dict12 =pd.DataFrame(dict12,index=[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq6f8jHjxtZD"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot((gb_y_pred2), color = 'r')\n",
        "plt.plot(np.array(Y_test), color = 'y')\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('Test Data')\n",
        "plt.title('Gradient Boosting')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIfBk3PGzZhB"
      },
      "outputs": [],
      "source": [
        "result=pd.concat([gb_dict11,gb_dict12],keys=['Training set','Test set'])\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM2ZHPvD7Jo9"
      },
      "outputs": [],
      "source": [
        "gb.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw9UJkRk7M6m"
      },
      "outputs": [],
      "source": [
        "importances = gb.feature_importances_\n",
        "\n",
        "importance_dict = {'Feature' : list(X_train.columns),\n",
        "                   'Feature Importance' : importances}\n",
        "\n",
        "importance_df = pd.DataFrame(importance_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axmGR2RT7Vms"
      },
      "outputs": [],
      "source": [
        "importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKaewoaU7Y24"
      },
      "outputs": [],
      "source": [
        "importance_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoBOMLQd7cOy"
      },
      "outputs": [],
      "source": [
        "importance_df.sort_values(by=['Feature Importance'],ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4W5iUnu7e8J"
      },
      "outputs": [],
      "source": [
        "gb.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKCnUTfr7mYT"
      },
      "outputs": [],
      "source": [
        "features = X_train.columns\n",
        "importances = gb.feature_importances_\n",
        "indices = np.argsort(importances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjWqlzRe7n9R"
      },
      "outputs": [],
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(10,20))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='blue', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of trees\n",
        "n_estimators = [50,80,100]\n",
        "\n",
        "# Maximum depth of trees\n",
        "max_depth = [4,6,8]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [50,100,150]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [40,50]\n",
        "\n",
        "# HYperparameter Grid\n",
        "param_dict = {'n_estimators' : n_estimators,\n",
        "              'max_depth' : max_depth,\n",
        "              'min_samples_split' : min_samples_split,\n",
        "              'min_samples_leaf' : min_samples_leaf}"
      ],
      "metadata": {
        "id": "UxnHy0kDi85U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_dict"
      ],
      "metadata": {
        "id": "zOJv9otajMTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Create an instance of the GradientBoostingRegressor\n",
        "gb_model = GradientBoostingRegressor()\n",
        "\n",
        "# Grid search\n",
        "gb_grid = GridSearchCV(estimator=gb_model,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 5, verbose=2)\n",
        "\n",
        "gb_grid.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "7iI3Jb7ejPcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_optimal_model = gb_grid.best_estimator_"
      ],
      "metadata": {
        "id": "2r0QPKH6jY4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_grid.best_params_"
      ],
      "metadata": {
        "id": "75qNAAdLl92H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on train and test data\n",
        "y_pred_train_g_g = gb_optimal_model.predict(X_train)\n",
        "y_pred_g_g= gb_optimal_model.predict(X_test)"
      ],
      "metadata": {
        "id": "09w8EjBMmCdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(\"Model Score:\",gb_optimal_model.score(X_train,Y_train))\n",
        "print(f\"Grid search CV: evaluation metrics on the traning set:\")\n",
        "MSE_gbh= mean_squared_error(Y_train, y_pred_train_g_g)\n",
        "print(\"MSE :\",MSE_gbh)\n",
        "\n",
        "RMSE_gbh=np.sqrt(MSE_gbh)\n",
        "print(\"RMSE :\",RMSE_gbh)\n",
        "\n",
        "\n",
        "MAE_gbh= mean_absolute_error(Y_train, y_pred_train_g_g)\n",
        "print(\"MAE :\",MAE_gbh)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "r2_gbh= r2_score(Y_train, y_pred_train_g_g)\n",
        "print(\"R2 :\",r2_gbh)\n",
        "Adjusted_R2_gbh = (1-(1-r2_score(Y_train, y_pred_train_g_g))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(Y_train, y_pred_train_g_g))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(f\"Grid search CV: evaluation metrics on the testing set:\")\n",
        "MSE_gbh= mean_squared_error(Y_test, y_pred_g_g)\n",
        "print(\"MSE :\",MSE_gbh)\n",
        "\n",
        "RMSE_gbh=np.sqrt(MSE_gbh)\n",
        "print(\"RMSE :\",RMSE_gbh)\n",
        "\n",
        "\n",
        "MAE_gbh= mean_absolute_error(Y_test, y_pred_g_g)\n",
        "print(\"MAE :\",MAE_gbh)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "r2_gbh= r2_score((Y_test), (y_pred_g_g))\n",
        "print(\"R2 :\",r2_gbh)\n",
        "Adjusted_R2_gbh = (1-(1-r2_score(Y_test, y_pred_g_g))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((Y_test), (y_pred_g_g)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "Qa_f8oblmaM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict13={'Model':'Gradient Boosting gridsearchcv ',\n",
        "       'MAE':round((MAE_gbh),3),\n",
        "       'MSE':round((MSE_gbh),3),\n",
        "       'RMSE':round((RMSE_gbh),3),\n",
        "       'R2_score':round((r2_gbh),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_gbh ),2)\n",
        "      }\n",
        "training_df=training_df.append(dict13,ignore_index=True)\n",
        "cv_dict13 =pd.DataFrame(dict13,index=[1])\n",
        "\n",
        "\n",
        "\n",
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict14={'Model':'Gradient Boosting gridsearchcv ',\n",
        "       'MAE':round((MAE_gbh),3),\n",
        "       'MSE':round((MSE_gbh),3),\n",
        "       'RMSE':round((RMSE_gbh),3),\n",
        "       'R2_score':round((r2_gbh),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_gbh ),2)\n",
        "      }\n",
        "test_df=test_df.append(dict14,ignore_index=True)\n",
        "cv_dict14 =pd.DataFrame(dict14,index=[1])\n"
      ],
      "metadata": {
        "id": "iRPlJzonnghE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=pd.concat([cv_dict13,cv_dict14],keys=['Training set','Test set'])\n",
        "result"
      ],
      "metadata": {
        "id": "Goc_z0F9ns_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_g_g),(Y_test)-(y_pred_g_g))"
      ],
      "metadata": {
        "id": "rScMXOtRoVEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = gb_optimal_model.feature_importances_\n",
        "\n",
        "importance_dict = {'Feature' : list(X_train.columns),\n",
        "                   'Feature Importance' : importances}\n",
        "\n",
        "importance_df = pd.DataFrame(importance_dict)"
      ],
      "metadata": {
        "id": "S7lV5a1FofFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_optimal_model.feature_importances_"
      ],
      "metadata": {
        "id": "a8TGXbAKocbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)"
      ],
      "metadata": {
        "id": "cIHiNJBhoi_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df.head()"
      ],
      "metadata": {
        "id": "Rnw-gvX6omy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df.sort_values(by=['Feature Importance'],ascending=False)"
      ],
      "metadata": {
        "id": "Er6nB-OSoqD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_model.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "8Vs93yh5osD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = X_train.columns\n",
        "importances = gb_model.feature_importances_\n",
        "indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "zy42z0MYow62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(10,20))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='blue', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oFYjfXqfoz4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amEn2htuzhCU"
      },
      "source": [
        "# Evaluation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F09hjNHBzejH"
      },
      "outputs": [],
      "source": [
        "result=pd.concat([training_df,test_df],keys=['Training set','Test set'])\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXRdxBeDzjlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15seTgn4_NES"
      },
      "source": [
        "# **Observation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o2UyA9_9YLl"
      },
      "source": [
        "During the time of our analysis, we initially did EDA on all the features of our datset. We first analysed our dependent variable, 'Rented Bike Count' and also transformed it. Next we analysed categorical variable and dropped the variable who had majority of one class, we also analysed numerical variable, found out the correlation, distribution and their relationship with the dependent variable. We also removed some numerical features who had mostly 0 values and hot encoded the categorical variables.\n",
        "\n",
        "Next we implemented 7 machine learning algorithms Linear Regression,lasso,ridge,elasticnet,decission tree, Random Forest and XGBoost. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-slbLfXE-MFp"
      },
      "source": [
        "There's a high correlation between the dependent variables specifically temperature.\n",
        "\n",
        "Temperature, Wind Speed, Solar Radiation, Visibility are positively correlated with the target variable.\n",
        "\n",
        "In general people used rented bikes during their commuting hours i.e. from 7am to 9am in morning and 5pm to 7pm in the evening.\n",
        "\n",
        "Weekdays are the ones where the demand of the bikes is comparatively high as compared with the weekends.\n",
        "\n",
        "Summer season was the most preferred season throughout the year where the count was very high. \n",
        "\n",
        "\n",
        "After performing the various models. Random Forest and Gradient boosting found to be the best model that can be used for the Bike Sharing Demand Prediction since the performance metrics (mse,rmse) shows lower and (r2,adjusted_r2) shows a higher value for both models!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlHucf8J9x_b"
      },
      "source": [
        "# Final Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mja-kqVb6j7B"
      },
      "source": [
        "We can use either Random Forest or Gradient boosting model for the bike rental stations. Since both the Regressor with Grid Search CV gave us the best results. Therefore, we can deploy it for our predictions. Also, As this data is time dependent, the values for \n",
        "variables will not always be consistent. Therefore, we need constantly keep checking for the models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y06xIdG26kRF"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}